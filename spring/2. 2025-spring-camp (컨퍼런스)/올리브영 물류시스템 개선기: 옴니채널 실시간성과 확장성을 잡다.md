[ 올리브영 물류시스템 개선기: 옴니채널 실시간성과 확장성을 잡다 ]

도메인:
1. 올리브영: 물류/발주 담당자 > 협력사 발주 > 납품 확정 > 상품 입고 예정

2. 물류센터: 센터 입고 > 입고 주문 수신 > 입고 확정 > 재고 적치 OR 센터 재고 반영

3. 올리브영: 센터 재고 반영 > 온라인 재고, 오프라인재고 < 오프라인, 온라인 몰 , 오늘드림 / 입고 확정 > 센터 입고 실적 < 물류/발주 담당자 

납품 확정하면 발주/주문 테이블 DB에 입력 > 배치 프로세스에서 최신 주문 계속 인식 > 센터 입/출고 주문 인터페이스 table 적재 > 센터 발주-주문 TABLE 2차 적재

배치와 엔터프라이즈 애플리케이션 통합(EAI)이 각각 30분 주기로 실행, 데이터가 올리브영 물류센터로 연동되기까지 최소 1시간의 지연 발생

지연 > 입고 포기 > 결품 발생 > 매출 하락 OR 배송 지연

이걸 해결하고자 kafka 도입해서 중간 과정 다 없앳음 > 데이터 신리도 향상, 데이터 지연 떨어짐

배치, eai 연동 방식 주요 한계
- 실시간성 미흡으로 정합성 보장 어려움
- 30분, 1시간 축적된 데이터 한번에 처리하면 성능 저하 및 시스템 부하 유발 > 장애도 전파 가능
- 장애 복구의 비효율성 > 중간에 장애나면 단계별로 다 복구하고 처음부터 배치 실행해야함 > 업체에서 1시간 대기 더 생김
- 운영 복잡성 증가 > 운영하는 회사가 달라서 힘듬

(실패한 메세지도 놓치지 않는 DLQ 백업 프로세스)
- 슬랙 알람 and xlsx 데이터 백업
- dead letter에 담아서 남겨둠

데이터 연동 속도도 엄청 좋아짐

KAFKA로 구현한 후에 이슈나 모니터링
- 출고처리는 보통 새벽에(모니터링 취약한 시점)
- 배치가 돌아가고 그다음에 출고처리가 들어옴 > 재고 들어왔는데 SOLD OUT
- 그럼 어떻게해? > 당직 서서 DB들어가서 SELECT 처리 잘 됐는지 확인
이를 해결하기 위해서
- 실시간 모니터링 > 이상 징후 조기에 탐지
- 온콜(ON CALL - 99%이하면 실시) > 전화 받을떄까지 전화
장애 모니터링 과정
- 데이터 센터 직접 들어가서 로그 확인 > 어플리케이션 로그/성능 모니터링 and 슬랙 에러 알람 and Data dog System ECS Dashboard



[ 실시간성과 확장성을 위한 RDB 중심 구조의 탈피 ]

온라인 재고
- 대한통운 물류센터 재고 변동 > 올리브영 온라인 서버 재고를 IF로 싱크
- 약 2만개 종류 재고

오프라인 재고
- 올리브영 매장의 재고
- 자사 시스템에서 변경되는 재고를 오프라인 DB에 직접 방영
- 상품 가짓 수 1,100만개

오늘 드림 서비스는 왜 오프라인 재고 조회 API 사용?
- 온라인 주문 했지만 주소지 가장 가까운 곳 재고 있으면 바로 배달대행사를 통해 보냄
- 6월 대규모 이벤트 장애 이벤트 발생
- 오프라인 DB부하의 직접적 원인은 오프라인 재고조회 API
- STOCK API 가 일평균 3000만개 호출 > 오프라인 디비 장애
- REDIS DB READ 따로 둬서 부하 줄이게

새로운 설계
- ORACLE REDIS 데이터싱크
- 

REDIS 도입하면서 3가지 이슈
- 동시성 제어 이슈 > REDIS의 분산락을 사용
- 조회 성능 이슈
>  MEMORY DB는 단건 조회에서 DISK 기반 ORACLE보다 성능상 우위
> 복수건 조회는 SCAN 기반 패턴 탐색으로 인해 ORACLE 대비 성능상 불리, 1천만개가 넘는 데이터
> REDIS 데이터 셋을 3개로 구성
> Stock Hash Key, Store Hash Key, Product Hash Key
- 안정성 이슈
> Redis 클러스터 장애 상황에서 어떻게 안정성을 보장할 것인가? 휘발성 db라
> 시스템 장애 감지 호출을 차단하고 대체 경로를 사용하게 해주는 CIRCUIT BREAKER 사용(장애 방지 패턴)
> 

도메인과 고객 경험을 이해한 설계 없이는, 어떤 기술도 성능을 보장하지 않습니다.... 캬
