[ Spring 으로 ML 서빙하기 ]

프로덕션에서 Python이 가지는 어려움
- 성능 및 병렬처리 제약
- 패키지 및 환경 관리 복잡성
- 대규모 서비스의 운영 한계

대안1: ML 추론 서버/엔진 사용 (이것도 어려움)
- 구축 및 운영 복잡성
- 벤더 종속성 및 기술 지원 한계
- 리소스 및 비용 부담

대안2: JVM에서 ML 서빙하면 좋은 장점(다 알지..)

HOW?
ONNX, TensorFlow > 저수준, 고성능
 DJL > 고수준, 추상화

DJL 사용하면 AI, ML 전문가 아니여도 할수있다.
DJL 내부에서 감성, 텍스트 분석 등 다양한 모델 지원 + Hugging Face랑 연결 돼있음.
ex) 리뷰분석, 한줄로 NLP랑 근정인지 부정인지 판단 가능.

DJL을 통한 JVM에서의 ML 서빙 한계
- CPU 48코어 할당하기도 하고
- 메모리를 몇 백긱 ㅏ할당하기도 하고
- 하드웨어 성능을 0.000001%까지 쥐어짜야함
>>> 그래서 ONNX, TensorFlow 같은 저수준을 사용해서 고성능을 내야함

TensorFlow 사용하면 저수준 설정 가능함
- 하드웨어(까먹음 메모리?) 얼마나 사용 할지
- GPU 병렬처리 직접 설정 가능
- 동적 처리 배치 설정 가능
- 제로카피 메모리 최적화

BUT, 일일이 모델 구조 만들고 설정해야함 > 1000만개 문서 탐색해서 관련 있는 문서 추출 1초도 안걸린다....

1. 어떤 경우에 반드시 파이썬으로 서빙 해야지?
- 라이브러리 써야하는데 그게 파이썬에만 있을때. > 그럼 파이썬이랑 JVM을 동시에 사용하는 상황이 생길텐데?
- 맞다 필수가결하게 생길거 같다.

2. 요청이 일반 웹 호출 과정과 다를 텐데 신경써야할 부분이 있는지?
- 스케일 업이 좋음. 

3. 회사에서 쓸만한 ML을 구축하려면 CPU, 코어나 이런 최소 비용은?
-  어떤 ML인지에 따라, SSL인지? 따라 다름 > 클라우드 환경에서 구축하는지, 하드웨어를 따로 구해서 구축하는지. SaaS, 온프레미스? 둘다 다함.
